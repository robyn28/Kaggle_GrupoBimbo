{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-notebook-rough-draft for final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am working on the Kaggle Grupo Bimbo competition dataset for this project. \n",
    "Link to Grupo Bimbo Kaggle competition: [Kaggle-GrupoBimbo](https://www.kaggle.com/c/grupo-bimbo-inventory-demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "#QUESTION - what is diff bw random forest classifier and rf regressor?\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", font_scale=1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/images/workflow/data-science-workflow-01.png)\n",
    "\n",
    "## Part 1. Identify the Problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: Given various sales/client/product data, we want to predict demand for each product at each store on a weekly basis. Per the train dataset, the average demand for a product at a store per week is 7.2 units. However, this does not factor in cases in which store managers under-predict demand for a product which we can see when returns=0 for that week. There are 74,180,464 records in the train data, of which 71,636,003 records have returns=0 or approx 96%. This generally means that managers probably often under predict product demand (unless that are exact on the money, which seems unlikely). \n",
    "\n",
    "**Goals**: The goal is to predict demand for each product at each store on a weekly basis while avoiding under-predicting demand.\n",
    "\n",
    "**Hypothesis**: As stated previously, the average product demand at a store per week is 7.2 units per the train data. However, given the likelihood of managers underpredicint product demand, I hypothesize a good model should return a number higher than 7.2 units to more accurately predict demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/images/workflow/data-science-workflow-02.png)\n",
    "\n",
    "## Part 2. Acquire the Data\n",
    "\n",
    "Kaggle has provided five files for this dataset:  \n",
    "_train.csv_: Use for building a model (contains target variable \"Demanda_uni_equil\")  \n",
    "_test.csv_: Use for submission file (fill in for target variable \"Demanda_uni_equil\")\n",
    "_cliente_tabla.csv_: Contains client names (can be joined with train/test on Cliente_ID)\n",
    "_producto_tabla.csv_: Contains product names (can be join with train/test on Producto_ID)\n",
    "_town_state.csv_: Contains town and state (can be join with train/test on Agencia_ID)\n",
    "\n",
    "\n",
    "**Notes**: I will further split _train.csv_ to generate my own cross validation set. However, I will use all of _train.csv_ to train my final model since Kaggle has already supplied a test dataset. Additionally, I am only using a random 10% of the train data given to me for EDA and model development. Using the entire train dataset proved to be too time consuming for the quick iternations needed for initial modeling building and EDA efforts. I plan to use 100% of the train dataset once I build a model I'm comfortable with. I may have to explore using EC2 for this effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>4619860</td>\n",
       "      <td>1150</td>\n",
       "      <td>2</td>\n",
       "      <td>27.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>4619860</td>\n",
       "      <td>1160</td>\n",
       "      <td>1</td>\n",
       "      <td>18.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>4619860</td>\n",
       "      <td>1182</td>\n",
       "      <td>4</td>\n",
       "      <td>55.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>4683304</td>\n",
       "      <td>1109</td>\n",
       "      <td>2</td>\n",
       "      <td>30.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>4683304</td>\n",
       "      <td>1125</td>\n",
       "      <td>7</td>\n",
       "      <td>67.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1112         1      1210     4619860         1150   \n",
       "1       3        1112         1      1210     4619860         1160   \n",
       "2       3        1112         1      1210     4619860         1182   \n",
       "3       3        1112         1      1210     4683304         1109   \n",
       "4       3        1112         1      1210     4683304         1125   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \n",
       "0              2      27.92                0          0.0                  2  \n",
       "1              1      18.86                0          0.0                  1  \n",
       "2              4      55.76                0          0.0                  4  \n",
       "3              2      30.02                0          0.0                  2  \n",
       "4              7      67.20                0          0.0                  7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train data\n",
    "# Given size of training data, I chose to use only 10% for speed reasons\n",
    "# QUESTION - how can i randomize with python? i used sql to create the random sample below.\n",
    "df_train = pd.read_csv(\"train_random10percent.csv\")\n",
    "\n",
    "# Check head\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4037</td>\n",
       "      <td>1</td>\n",
       "      <td>2209</td>\n",
       "      <td>4639078</td>\n",
       "      <td>35305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2237</td>\n",
       "      <td>1</td>\n",
       "      <td>1226</td>\n",
       "      <td>4705135</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2045</td>\n",
       "      <td>1</td>\n",
       "      <td>2831</td>\n",
       "      <td>4549769</td>\n",
       "      <td>32940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1227</td>\n",
       "      <td>1</td>\n",
       "      <td>4448</td>\n",
       "      <td>4717855</td>\n",
       "      <td>43066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1219</td>\n",
       "      <td>1</td>\n",
       "      <td>1130</td>\n",
       "      <td>966351</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID\n",
       "0   0      11        4037         1      2209     4639078        35305\n",
       "1   1      11        2237         1      1226     4705135         1238\n",
       "2   2      10        2045         1      2831     4549769        32940\n",
       "3   3      11        1227         1      4448     4717855        43066\n",
       "4   4      11        1219         1      1130      966351         1277"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Check head. I noticed that I will have to drop certain columns so that test and train sets have the same features. \n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Semana_mean</th>\n",
       "      <th>Agencia_ID_mean</th>\n",
       "      <th>Canal_ID_mean</th>\n",
       "      <th>Ruta_SAK_mean</th>\n",
       "      <th>Cliente_ID_mean</th>\n",
       "      <th>Venta_uni_hoy_mean</th>\n",
       "      <th>Venta_hoy_mean</th>\n",
       "      <th>Dev_uni_proxima_mean</th>\n",
       "      <th>Dev_proxima_mean</th>\n",
       "      <th>Demanda_uni_equil_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2257.714286</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3476.428571</td>\n",
       "      <td>9.927571e+05</td>\n",
       "      <td>261.857143</td>\n",
       "      <td>4733.798571</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>116.550000</td>\n",
       "      <td>261.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1868.818182</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7614.636364</td>\n",
       "      <td>2.606382e+06</td>\n",
       "      <td>219.909091</td>\n",
       "      <td>3144.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>6.139906</td>\n",
       "      <td>2569.569063</td>\n",
       "      <td>1.085722</td>\n",
       "      <td>2370.468701</td>\n",
       "      <td>1.505971e+06</td>\n",
       "      <td>4.918930</td>\n",
       "      <td>18.179211</td>\n",
       "      <td>0.083738</td>\n",
       "      <td>0.307245</td>\n",
       "      <td>4.869604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>6.032710</td>\n",
       "      <td>2207.965045</td>\n",
       "      <td>1.183846</td>\n",
       "      <td>1291.151503</td>\n",
       "      <td>1.302741e+06</td>\n",
       "      <td>3.213304</td>\n",
       "      <td>68.875936</td>\n",
       "      <td>0.077698</td>\n",
       "      <td>1.659034</td>\n",
       "      <td>3.140966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>5.928571</td>\n",
       "      <td>1827.500000</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>3385.714286</td>\n",
       "      <td>2.014600e+06</td>\n",
       "      <td>10.642857</td>\n",
       "      <td>190.905714</td>\n",
       "      <td>9.642857</td>\n",
       "      <td>209.871429</td>\n",
       "      <td>10.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Producto_ID  Semana_mean  Agencia_ID_mean  Canal_ID_mean  Ruta_SAK_mean  \\\n",
       "0           41     6.500000      2257.714286       7.000000    3476.428571   \n",
       "1           53     7.000000      1868.818182       4.000000    7614.636364   \n",
       "2           72     6.139906      2569.569063       1.085722    2370.468701   \n",
       "3           73     6.032710      2207.965045       1.183846    1291.151503   \n",
       "4          100     5.928571      1827.500000       7.428571    3385.714286   \n",
       "\n",
       "   Cliente_ID_mean  Venta_uni_hoy_mean  Venta_hoy_mean  Dev_uni_proxima_mean  \\\n",
       "0     9.927571e+05          261.857143     4733.798571              6.428571   \n",
       "1     2.606382e+06          219.909091     3144.700000              0.000000   \n",
       "2     1.505971e+06            4.918930       18.179211              0.083738   \n",
       "3     1.302741e+06            3.213304       68.875936              0.077698   \n",
       "4     2.014600e+06           10.642857      190.905714              9.642857   \n",
       "\n",
       "   Dev_proxima_mean  Demanda_uni_equil_mean  \n",
       "0        116.550000              261.857143  \n",
       "1          0.000000              219.909091  \n",
       "2          0.307245                4.869604  \n",
       "3          1.659034                3.140966  \n",
       "4        209.871429               10.642857  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#given that i cannot use a significant amount of variables in train data, i created additoinal features using the mean\n",
    "#i grouped on product id since i will ultimately be predicting demand for each product\n",
    "\n",
    "df_train_mean = df_train.groupby('Producto_ID').mean().add_suffix('_mean').reset_index()\n",
    "df_train_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>Venta_uni_hoy_mean</th>\n",
       "      <th>Demanda_uni_equil_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6683451</th>\n",
       "      <td>9</td>\n",
       "      <td>4040</td>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>425736</td>\n",
       "      <td>43118</td>\n",
       "      <td>1</td>\n",
       "      <td>9.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.430301</td>\n",
       "      <td>4.371233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6617790</th>\n",
       "      <td>9</td>\n",
       "      <td>1471</td>\n",
       "      <td>1</td>\n",
       "      <td>1140</td>\n",
       "      <td>909746</td>\n",
       "      <td>43207</td>\n",
       "      <td>10</td>\n",
       "      <td>30.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>14.659612</td>\n",
       "      <td>14.605897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116578</th>\n",
       "      <td>9</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>1042</td>\n",
       "      <td>990227</td>\n",
       "      <td>2233</td>\n",
       "      <td>11</td>\n",
       "      <td>219.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5.679594</td>\n",
       "      <td>5.626612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748965</th>\n",
       "      <td>6</td>\n",
       "      <td>1147</td>\n",
       "      <td>4</td>\n",
       "      <td>6612</td>\n",
       "      <td>4410563</td>\n",
       "      <td>4245</td>\n",
       "      <td>3</td>\n",
       "      <td>35.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.101097</td>\n",
       "      <td>3.974700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259099</th>\n",
       "      <td>6</td>\n",
       "      <td>3213</td>\n",
       "      <td>1</td>\n",
       "      <td>1435</td>\n",
       "      <td>48194</td>\n",
       "      <td>1242</td>\n",
       "      <td>7</td>\n",
       "      <td>53.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.096787</td>\n",
       "      <td>5.057117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "6683451       9        4040         1      1107      425736        43118   \n",
       "6617790       9        1471         1      1140      909746        43207   \n",
       "3116578       9        1631         1      1042      990227         2233   \n",
       "4748965       6        1147         4      6612     4410563         4245   \n",
       "2259099       6        3213         1      1435       48194         1242   \n",
       "\n",
       "         Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  \\\n",
       "6683451              1       9.91                0          0.0   \n",
       "6617790             10      30.20                0          0.0   \n",
       "3116578             11     219.34                0          0.0   \n",
       "4748965              3      35.76                0          0.0   \n",
       "2259099              7      53.48                0          0.0   \n",
       "\n",
       "         Demanda_uni_equil  Venta_uni_hoy_mean  Demanda_uni_equil_mean  \n",
       "6683451                  1            4.430301                4.371233  \n",
       "6617790                 10           14.659612               14.605897  \n",
       "3116578                 11            5.679594                5.626612  \n",
       "4748965                  3            4.101097                3.974700  \n",
       "2259099                  7            5.096787                5.057117  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from above, adding 2 additional features, the average sales units and the average demand\n",
    "df_train2 = df_train.merge(df_train_mean[['Producto_ID','Venta_uni_hoy_mean', 'Demanda_uni_equil_mean']],how='inner',on='Producto_ID')\n",
    "df_train2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy_mean</th>\n",
       "      <th>Demanda_uni_equil_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4037</td>\n",
       "      <td>1</td>\n",
       "      <td>2209</td>\n",
       "      <td>4639078</td>\n",
       "      <td>35305</td>\n",
       "      <td>9.171683</td>\n",
       "      <td>9.132431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2237</td>\n",
       "      <td>1</td>\n",
       "      <td>1226</td>\n",
       "      <td>4705135</td>\n",
       "      <td>1238</td>\n",
       "      <td>3.217857</td>\n",
       "      <td>3.161574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2045</td>\n",
       "      <td>1</td>\n",
       "      <td>2831</td>\n",
       "      <td>4549769</td>\n",
       "      <td>32940</td>\n",
       "      <td>4.042903</td>\n",
       "      <td>4.018765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1227</td>\n",
       "      <td>1</td>\n",
       "      <td>4448</td>\n",
       "      <td>4717855</td>\n",
       "      <td>43066</td>\n",
       "      <td>2.499306</td>\n",
       "      <td>2.439875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1219</td>\n",
       "      <td>1</td>\n",
       "      <td>1130</td>\n",
       "      <td>966351</td>\n",
       "      <td>1277</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0   0      11        4037         1      2209     4639078        35305   \n",
       "1   1      11        2237         1      1226     4705135         1238   \n",
       "2   2      10        2045         1      2831     4549769        32940   \n",
       "3   3      11        1227         1      4448     4717855        43066   \n",
       "4   4      11        1219         1      1130      966351         1277   \n",
       "\n",
       "   Venta_uni_hoy_mean  Demanda_uni_equil_mean  \n",
       "0            9.171683                9.132431  \n",
       "1            3.217857                3.161574  \n",
       "2            4.042903                4.018765  \n",
       "3            2.499306                2.439875  \n",
       "4            1.500000                1.500000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding features to the test set in order to match train set\n",
    "df_test2 = df_test.merge(df_train_mean[['Producto_ID','Venta_uni_hoy_mean', 'Demanda_uni_equil_mean']],how='left',on='Producto_ID')\n",
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/images/workflow/data-science-workflow-03-05.png)\n",
    "\n",
    "## Part 3. Parse, Mine, and Refine the data\n",
    "\n",
    "Perform exploratory data analysis and verify the quality of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check columns and counts to drop any non-generic or near-empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset columns:\n",
      "['Semana' 'Agencia_ID' 'Canal_ID' 'Ruta_SAK' 'Cliente_ID' 'Producto_ID'\n",
      " 'Venta_uni_hoy' 'Venta_hoy' 'Dev_uni_proxima' 'Dev_proxima'\n",
      " 'Demanda_uni_equil' 'Venta_uni_hoy_mean' 'Demanda_uni_equil_mean']\n",
      "\n",
      "test dataset columns:\n",
      "['id' 'Semana' 'Agencia_ID' 'Canal_ID' 'Ruta_SAK' 'Cliente_ID'\n",
      " 'Producto_ID' 'Venta_uni_hoy_mean' 'Demanda_uni_equil_mean']\n"
     ]
    }
   ],
   "source": [
    "# Check columns\n",
    "print \"train dataset columns:\"\n",
    "print df_train2.columns.values\n",
    "print \n",
    "print \"test dataset columns:\"\n",
    "print df_test2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset counts:\n",
      "Semana                    7413317\n",
      "Agencia_ID                7413317\n",
      "Canal_ID                  7413317\n",
      "Ruta_SAK                  7413317\n",
      "Cliente_ID                7413317\n",
      "Producto_ID               7413317\n",
      "Venta_uni_hoy             7413317\n",
      "Venta_hoy                 7413317\n",
      "Dev_uni_proxima           7413317\n",
      "Dev_proxima               7413317\n",
      "Demanda_uni_equil         7413317\n",
      "Venta_uni_hoy_mean        7413317\n",
      "Demanda_uni_equil_mean    7413317\n",
      "dtype: int64\n",
      "\n",
      "test dataset counts:\n",
      "id                        6999251\n",
      "Semana                    6999251\n",
      "Agencia_ID                6999251\n",
      "Canal_ID                  6999251\n",
      "Ruta_SAK                  6999251\n",
      "Cliente_ID                6999251\n",
      "Producto_ID               6999251\n",
      "Venta_uni_hoy_mean        6955480\n",
      "Demanda_uni_equil_mean    6955480\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check counts\n",
    "print \"train dataset counts:\"\n",
    "print df_train2.count()\n",
    "print\n",
    "print \"test dataset counts:\"\n",
    "print df_test2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values and drop or impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset missing values:\n",
      "Semana                    0\n",
      "Agencia_ID                0\n",
      "Canal_ID                  0\n",
      "Ruta_SAK                  0\n",
      "Cliente_ID                0\n",
      "Producto_ID               0\n",
      "Venta_uni_hoy             0\n",
      "Venta_hoy                 0\n",
      "Dev_uni_proxima           0\n",
      "Dev_proxima               0\n",
      "Demanda_uni_equil         0\n",
      "Venta_uni_hoy_mean        0\n",
      "Demanda_uni_equil_mean    0\n",
      "dtype: int64\n",
      "\n",
      "test dataset missing values:\n",
      "id                            0\n",
      "Semana                        0\n",
      "Agencia_ID                    0\n",
      "Canal_ID                      0\n",
      "Ruta_SAK                      0\n",
      "Cliente_ID                    0\n",
      "Producto_ID                   0\n",
      "Venta_uni_hoy_mean        43771\n",
      "Demanda_uni_equil_mean    43771\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check counts for missing values in each column\n",
    "print \"train dataset missing values:\"\n",
    "print df_train2.isnull().sum()\n",
    "print\n",
    "print \"test dataset missing values:\"\n",
    "print df_test2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangle the data to address any issues from above checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>Venta_uni_hoy_mean</th>\n",
       "      <th>Demanda_uni_equil_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4619860</td>\n",
       "      <td>1150</td>\n",
       "      <td>2</td>\n",
       "      <td>6.242652</td>\n",
       "      <td>6.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1723873</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "      <td>6.242652</td>\n",
       "      <td>6.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4314785</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "      <td>6.242652</td>\n",
       "      <td>6.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66252</td>\n",
       "      <td>1150</td>\n",
       "      <td>3</td>\n",
       "      <td>6.242652</td>\n",
       "      <td>6.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>210290</td>\n",
       "      <td>1150</td>\n",
       "      <td>17</td>\n",
       "      <td>6.242652</td>\n",
       "      <td>6.191044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Cliente_ID  Producto_ID  Demanda_uni_equil  Venta_uni_hoy_mean  \\\n",
       "0       3     4619860         1150                  2            6.242652   \n",
       "1       3     1723873         1150                  1            6.242652   \n",
       "2       3     4314785         1150                  1            6.242652   \n",
       "3       3       66252         1150                  3            6.242652   \n",
       "4       3      210290         1150                 17            6.242652   \n",
       "\n",
       "   Demanda_uni_equil_mean  \n",
       "0                6.191044  \n",
       "1                6.191044  \n",
       "2                6.191044  \n",
       "3                6.191044  \n",
       "4                6.191044  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns not included in test dataset\n",
    "df_train2 = df_train2.drop(['Venta_uni_hoy', 'Venta_hoy', 'Dev_uni_proxima', 'Dev_proxima'], axis=1)\n",
    "\n",
    "# Check data\n",
    "df_train2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset missing values:\n",
      "id                        0\n",
      "Semana                    0\n",
      "Cliente_ID                0\n",
      "Producto_ID               0\n",
      "Venta_uni_hoy_mean        0\n",
      "Demanda_uni_equil_mean    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop blank values in test set and replace with mean\n",
    "\n",
    "# Replace missing values for venta_uni_hoy_mean using mean\n",
    "df_test2.loc[(df_test2['Venta_uni_hoy_mean'].isnull()), 'Venta_uni_hoy_mean'] = df_test2['Venta_uni_hoy_mean'].dropna().mean()\n",
    "\n",
    "# Replace missing values for demand using mean\n",
    "df_test2.loc[(df_test2['Demanda_uni_equil_mean'].isnull()), 'Demanda_uni_equil_mean'] = df_test2['Demanda_uni_equil_mean'].dropna().mean()\n",
    "\n",
    "print \"test dataset missing values:\"\n",
    "print df_test2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>Venta_uni_hoy_mean</th>\n",
       "      <th>Demanda_uni_equil_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.413317e+06</td>\n",
       "      <td>7.413317e+06</td>\n",
       "      <td>7.413317e+06</td>\n",
       "      <td>7.413317e+06</td>\n",
       "      <td>7.413317e+06</td>\n",
       "      <td>7.413317e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.950245e+00</td>\n",
       "      <td>1.802524e+06</td>\n",
       "      <td>2.083868e+04</td>\n",
       "      <td>7.218393e+00</td>\n",
       "      <td>7.304598e+00</td>\n",
       "      <td>7.218393e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.013394e+00</td>\n",
       "      <td>2.362439e+06</td>\n",
       "      <td>1.866494e+04</td>\n",
       "      <td>2.164558e+01</td>\n",
       "      <td>1.192780e+01</td>\n",
       "      <td>1.176922e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.567670e+05</td>\n",
       "      <td>1.242000e+03</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.287170e+00</td>\n",
       "      <td>3.235731e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.193440e+06</td>\n",
       "      <td>3.054900e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.321605e+00</td>\n",
       "      <td>5.306513e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.371366e+06</td>\n",
       "      <td>3.742700e+04</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>7.343644e+00</td>\n",
       "      <td>7.316136e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.015152e+09</td>\n",
       "      <td>4.999700e+04</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>3.000000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Semana    Cliente_ID   Producto_ID  Demanda_uni_equil  \\\n",
       "count  7.413317e+06  7.413317e+06  7.413317e+06       7.413317e+06   \n",
       "mean   5.950245e+00  1.802524e+06  2.083868e+04       7.218393e+00   \n",
       "std    2.013394e+00  2.362439e+06  1.866494e+04       2.164558e+01   \n",
       "min    3.000000e+00  2.600000e+01  4.100000e+01       0.000000e+00   \n",
       "25%    4.000000e+00  3.567670e+05  1.242000e+03       2.000000e+00   \n",
       "50%    6.000000e+00  1.193440e+06  3.054900e+04       3.000000e+00   \n",
       "75%    8.000000e+00  2.371366e+06  3.742700e+04       6.000000e+00   \n",
       "max    9.000000e+00  2.015152e+09  4.999700e+04       5.000000e+03   \n",
       "\n",
       "       Venta_uni_hoy_mean  Demanda_uni_equil_mean  \n",
       "count        7.413317e+06            7.413317e+06  \n",
       "mean         7.304598e+00            7.218393e+00  \n",
       "std          1.192780e+01            1.176922e+01  \n",
       "min          0.000000e+00            0.000000e+00  \n",
       "25%          3.287170e+00            3.235731e+00  \n",
       "50%          5.321605e+00            5.306513e+00  \n",
       "75%          7.343644e+00            7.316136e+00  \n",
       "max          3.000000e+03            3.000000e+03  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary statistics for data\n",
    "df_train2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x39f0be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARkAAAEZCAYAAACjEFEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f2e0748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show box plot of demand by week\n",
    "sns.factorplot(\n",
    "    x='Semana',\n",
    "    y='Demanda_uni_equil',\n",
    "    data=df_train2,\n",
    "    kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and convert all data types to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semana                 int64\n",
       "Agencia_ID             int64\n",
       "Canal_ID               int64\n",
       "Ruta_SAK               int64\n",
       "Cliente_ID             int64\n",
       "Producto_ID            int64\n",
       "Venta_uni_hoy          int64\n",
       "Venta_hoy            float64\n",
       "Dev_uni_proxima        int64\n",
       "Dev_proxima          float64\n",
       "Demanda_uni_equil      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "df_train.dtypes\n",
    "\n",
    "#these are all numerical but are not continuous values and therefore don't have relative significant to one another, except for week\n",
    "#however, creating dummy variables for all these is too memory intensive. as such, might have to explore using a random forest model\n",
    "#in addition to the linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/images/workflow/data-science-workflow-06.png)\n",
    "\n",
    "## Part 4. Build a Model\n",
    "\n",
    "Create a cross validation split, select and build a model, evaluate the model, and refine the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cross validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create cross validation sets\n",
    "\n",
    "#set target variable name\n",
    "target = 'Demanda_uni_equil'\n",
    "\n",
    "#set X and y\n",
    "X = df_train2.drop([target], axis=1)\n",
    "y = df_train2[target]\n",
    "\n",
    "# create separate training and test sets with 60/40 train/test split\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size= .4) \n",
    "\n",
    "#QUESTION - do i have to cross validate when using kaggle data? prob not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create linear regression object\n",
    "#lm = linear_model.LinearRegression()\n",
    "\n",
    "#create random forest object\n",
    "#rf = ensemble.RandomForestClassifier(n_estimators=10) - did not work due to memory errors during fitting\n",
    "rf = ensemble.RandomForestRegressor(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using the training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.260\n"
     ]
    }
   ],
   "source": [
    "# Check score on test set\n",
    "print \"Score: %0.3f\" % rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/images/workflow/data-science-workflow-07.png)\n",
    "\n",
    "## Part 5: Present the Results\n",
    "\n",
    "Generate summary of findings and kaggle submission file.\n",
    "\n",
    "NOTE: For the purposes of generating summary narratives and kaggle submission, we can train the model on the entire training data provided in _train.csv_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kaggle training data and use entire data to train tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set target variable name\n",
    "target = 'Demanda_uni_equil'\n",
    "\n",
    "# Set X_train and y_train\n",
    "X_train = df_train2.drop([target], axis=1)\n",
    "y_train = df_train2[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.852\n"
     ]
    }
   ],
   "source": [
    "# Build tuned model\n",
    "#create linear regression object\n",
    "#lm = linear_model.LinearRegression()\n",
    "\n",
    "#create random forest object\n",
    "rf = ensemble.RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "#train the model using the training data\n",
    "#lm.fit(X_train,y_train)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "# Score tuned model\n",
    "print \"Score: %0.3f\" % rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kaggle test data, make predictions using model, and generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.999251e+06</td>\n",
       "      <td>6.999251e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.499625e+06</td>\n",
       "      <td>7.226255e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.020510e+06</td>\n",
       "      <td>1.171634e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.174964e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.749812e+06</td>\n",
       "      <td>3.271562e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.499625e+06</td>\n",
       "      <td>5.288983e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.249438e+06</td>\n",
       "      <td>7.380220e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.999250e+06</td>\n",
       "      <td>1.580665e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  Demanda_uni_equil\n",
       "count  6.999251e+06       6.999251e+06\n",
       "mean   3.499625e+06       7.226255e+00\n",
       "std    2.020510e+06       1.171634e+01\n",
       "min    0.000000e+00      -3.174964e+02\n",
       "25%    1.749812e+06       3.271562e+00\n",
       "50%    3.499625e+06       5.288983e+00\n",
       "75%    5.249438e+06       7.380220e+00\n",
       "max    6.999250e+06       1.580665e+03"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame for submission\n",
    "df_sub = df_test2[['id']]\n",
    "\n",
    "df_test2 = df_test2.drop('id', axis=1)\n",
    "\n",
    "#predict using tuned model\n",
    "df_sub['Demanda_uni_equil'] = lm.predict(df_test2)\n",
    "\n",
    "df_sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rwoodruff\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.999251e+06</td>\n",
       "      <td>6.999251e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.499625e+06</td>\n",
       "      <td>7.226666e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.020510e+06</td>\n",
       "      <td>1.171064e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.749812e+06</td>\n",
       "      <td>3.271562e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.499625e+06</td>\n",
       "      <td>5.288983e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.249438e+06</td>\n",
       "      <td>7.380220e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.999250e+06</td>\n",
       "      <td>1.580665e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  Demanda_uni_equil\n",
       "count  6.999251e+06       6.999251e+06\n",
       "mean   3.499625e+06       7.226666e+00\n",
       "std    2.020510e+06       1.171064e+01\n",
       "min    0.000000e+00       0.000000e+00\n",
       "25%    1.749812e+06       3.271562e+00\n",
       "50%    3.499625e+06       5.288983e+00\n",
       "75%    5.249438e+06       7.380220e+00\n",
       "max    6.999250e+06       1.580665e+03"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df_sub['Demanda_uni_equil']\n",
    "d[d<0] = 0\n",
    "df_sub.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write submission file\n",
    "df_sub.to_csv(\"mysubmission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Kaggle score** : \n",
    "using linear regression 0.75682\n",
    "using random forest: 0.76720\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#notes\n",
    "#want to try to use a classifier like random forest or logistic regression\n",
    "#do somethign wtih time series to check for seasonality or general trending?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
